/**
 * \package org.sleuthkit.autopsy.ingest
 *
 * The package provides the ingest module framework; the framework defines how ingest modules should behave and provides the infrastructure to execute them.
 * 
 * Different ingest modules module generally have its own specific role.  
 * The two main use cases for ingest modules are:
 * - to extract information from the image and write result to blackboard,
 * - to analyze data already in blackboard and add more information to it.
 * 
 * There may also be special-purpose ingest modules that run early in the ingest pipe-line.  Results posted by such modules can useful to subsequent modules.
 * One example of such module is Hash DB module, which determines which files are known; known files are generally treated differently.
 * For instance, processing of known files can be skipped by subsequent modules in the pipeline (if chosen so), for performance reasons.
 * 
 * The framework provides interfaces every ingest module needs to implement:
 * - org.sleuthkit.autopsy.ingest.IngestServiceImage (for modules that are interested in the image as a whole, or modules that selectively pick and analyze data from the image) 
 * - org.sleuthkit.autopsy.ingest.IngestServiceAbstractFile (for modules that should process every file in the image).
 * 
 * org.sleuthkit.autopsy.ingest.IngestServiceImage services run each in a separate thread, in parallel with respect to other image services.
 * File services execute within the same worker thread and they run in series; for every file in the image every file ingest service is invoked.
 *
 * org.sleuthkit.autopsy.ingest.IngestServiceAbstractFile services are singleton instances
 * and org.sleuthkit.autopsy.ingest.IngestServiceImage service are not singletons.  There could be multiple instances of 
 * an image based service, because multiple images can be analyzed at the same time by multiple instances of the same image service class
 * (NOTE: this design might change in the future to limit number of image services executing at the same time and to introduce a better service dependency system).
 *
 * The interfaces define methods to initialize, process passed in data, configure the ingest service, 
 * query the service state and finalize the service.
 * 
 * The framework also contains classes:
 * - org.sleuthkit.autopsy.ingest.IngestManager, the ingest manager, responsible for discovery of ingest modules, enqueuing work to the modules, starting and stopping the ingest pipeline, 
 * propagating messages sent from the ingest modules to other Autopsy components and is used to query ingest status.
 * - org.sleuthkit.autopsy.ingest.IngestManagerProxy, a facility (IngestManager facade) used by the modules to communicate with the manager,
 * - additional classes to support threading, sending messages, ingest monitoring, ingest cancellation, progress bars,
 * - a user interface component (Ingest Inbox) used to display interesting messages posted by ingest modules to the user,
 * 
 * 
 * Ingest modules run in background threads. There is a single background thread for file-level ingest modules, within which every file ingest module runs series for every file.
 * Image ingest modules run each in their own thread and thus can run in parallel (TODO we will change this in the future for performance reasons, and support image ingest module dependencies).  
 * Every ingest thread is presented with a progress bar and can be cancelled by a user, or by the framework, in case of a critical event (such as Autopsy is terminating, or a system error).
 *
 * Ingest module can maintain internal threads for any special processing that can occur in parallel.
 * However, the module is then responsible for creating, managing and tearing down the internal threads and to implement locking to protect critical sections internal to the module.
 * An example of a module that maintains its own threads is the KeywordSearch module.
 * 
 * org.sleuthkit.autopsy.ingest.IngestManager provides public API other modules can use to get ingest status updates.
 * A handle to ingest manager singleton instance is obtained using org.sleuthkit.autopsy.ingest.IngestManager.getDefault().
 * org.sleuthkit.autopsy.ingest.IngestManager.isIngestRunning() is used to check if any ingest modules are currently running.
 * There are more granular methods to check ingest status: org.sleuthkit.autopsy.ingest.IngestManager.isFileIngestRunning() to check if the file ingest pipeline is running,
 * org.sleuthkit.autopsy.ingest.IngestManager.isImageIngestRunning() to check the status of the image ingest pipeline,
 * org.sleuthkit.autopsy.ingest.IngestManager.isEnqueueRunning() to check if ingest is currently being enqueued,
 * and org.sleuthkit.autopsy.ingest.IngestManager.isServiceRunning() to check on a per-service level.
 *
 * External modules can also register themselves as ingest service event listeners and receive event notifications (when a service is started, stopped, completed or has new data).
 * Use a static org.sleuthkit.autopsy.ingest.IngestManager.addPropertyChangeListener() method to register a service event listener.
 * Events types received are defined in IngestManagerEvents enum.
 * IngestManagerEvents.SERVICE_HAS_DATA event type, a special type of event object is passed in org.sleuthkit.autopsy.ingest.ServiceDataEvent.
 * The object wraps a collection of blackboard artifacts and their associated attributes that are to be reported as the new data to listeners.
 * Passing the data as part of the event reduces memory footprint and decreases number of garbage collections 
 * of the blackboard artifacts and attributes objects (the objects are expected to be reused by the data event listeners).
 *
 * If a service does not pass the data as part of ServiceDataEvent (ServiceDataEvent.getArtifacts() returns null) - it is an indication that the service 
 * has new data but it does not implement new data tracking.  The listener can then perform a blackboard query to get the latest data of interest (e.g. by artifact type).
 *
 * Service name and artifact type for the collection of artifacts is also passed in as as part of the service data event.
 * By design, only a single type of artifacts can be contained in a single data event. 
 *
 * At the end of the ingest, org.sleuthkit.autopsy.ingest.IngestManager itself will notify all listeners of new data being available in the blackboard.
 * This ensures the listeners receive a new data notification, in case some of the modules fail to report availability of new data.
 * Nevertheless, ingest module developers are encouraged to generate new data events in order to provide the real-time feedback to the user.
 *
 * Refer to ingest.dox and org.sleuthkit.autopsy.ingest.example examples for more details on implementing custom ingest modules.
 *
 *
 * 
 * 
 * 
 */